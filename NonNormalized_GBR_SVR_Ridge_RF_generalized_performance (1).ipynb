{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kf0YnqSNmgTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xynYwHTkSWz"
      },
      "outputs": [],
      "source": [
        "# evaluate linear algorithms\n",
        "from numpy import load\n",
        "from numpy import loadtxt\n",
        "from numpy import nan\n",
        "from numpy import isnan\n",
        "from numpy import count_nonzero\n",
        "from numpy import unique\n",
        "from numpy import array\n",
        "from sklearn.base import clone\n",
        "from scipy.stats import sem\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "import math\n",
        "import datetime\n",
        "import time\n",
        "import numpy as np\n",
        "import scipy\n",
        "import random\n",
        "\n",
        "random.seed(10)\n",
        "\n",
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequences)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps_in\n",
        "\t\tout_end_ix = end_ix + n_steps_out-1\n",
        "\t\t# check if we are beyond the dataset\n",
        "\t\tif out_end_ix > len(sequences):\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_preferred_format(sec):\n",
        "    sec = sec % (24 * 3600)\n",
        "    hour = sec // 3600\n",
        "    sec %= 3600\n",
        "    min = sec // 60\n",
        "    sec %= 60\n",
        "#  print(\"seconds value in hours:\",hour)\n",
        "#  print(\"seconds value in minutes:\",min)\n",
        "\n",
        "#return \"%02d:%02d:%02d\" % (hour, min, sec)\n",
        "    return \"%02d:%02d\" % (hour, min)"
      ],
      "metadata": {
        "id": "07etnnwWlKIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_data = '/content/drive/MyDrive/NHANCE data analysis/NonNormalizedMergedData10min'\n",
        "merged_files = os.listdir(merged_data)"
      ],
      "metadata": {
        "id": "xHTt7oTpl6Zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = pd.DataFrame()"
      ],
      "metadata": {
        "id": "PGTT7-lVupKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "n_timesteps_in = 3\n",
        "n_timesteps_out = 3\n",
        "\n",
        "#parent_X = np.empty((1, n_timesteps_in, 26))\n",
        "parent_X = np.empty((1, n_timesteps_in,26))\n",
        "parent_y = np.empty((1, 3))\n",
        "\n",
        "for el in merged_files:\n",
        "  os.chdir(merged_data)\n",
        "  data = pd.read_csv(el)\n",
        "  data.drop(['Unnamed: 0','time_stamp','Fatigue Perception'], axis = 1, inplace = True)\n",
        "  data['Times'] =  pd.to_datetime(data['Times'])\n",
        "  data = data.set_index(['Times'])\n",
        "  data_1 = data.resample('1min').mean()\n",
        "  cols = list(data_1.columns)\n",
        "  cols = cols[1:]\n",
        "  data_1 = data_1[cols]\n",
        "  #all_data = all_data.append(data_1)\n",
        "  X, y = split_sequences(data_1.values, n_timesteps_in, n_timesteps_out)\n",
        "  parent_X = np.vstack((parent_X, X))\n",
        "\n",
        "  parent_y = np.vstack((parent_y, y))\n",
        "\n",
        "\n",
        "#sampling at 1 minute. Hence predicting, 1, 2 and 3 minutes into future\n",
        "all_err_lr_1 = []\n",
        "all_err_svr_1 = []\n",
        "all_err_gbr_1 = []\n",
        "all_err_rf_1 = []\n",
        "\n",
        "\n",
        "# convert dataset into input/output\n",
        "#X, y = split_sequences(all_data.values, n_timesteps_in, n_timesteps_out)\n",
        "X_train, X_test, y_train, y_test = train_test_split(parent_X, parent_y, test_size=0.2, shuffle= True)\n",
        "\n",
        "# convert 3D array into 2D\n",
        "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n",
        "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n",
        "\n",
        "model_linreg = Ridge()\n",
        "model_linreg.fit(X_train, y_train)\n",
        "y_predict_lr = model_linreg.predict(X_test)\n",
        "\n",
        "abs_err_lr = abs(y_predict_lr - y_test)\n",
        "#all_err_lr_1.append(abs_err_lr.mean(axis = 0))\n",
        "\n",
        "model_svr = MultiOutputRegressor(SVR())\n",
        "model_svr.fit(X_train, y_train)\n",
        "y_predict_svr = model_svr.predict(X_test)\n",
        "\n",
        "abs_err_svr = abs(y_predict_svr - y_test)\n",
        "#all_err_svr_1.append(abs_err_svr.mean(axis = 0))\n",
        "\n",
        "model_gbr = MultiOutputRegressor(GradientBoostingRegressor())\n",
        "model_gbr.fit(X_train, y_train)\n",
        "y_predict_gbr = model_gbr.predict(X_test)\n",
        "\n",
        "abs_err_gbr = abs(y_predict_gbr - y_test)\n",
        "#all_err_gbr_1.append(abs_err_gbr.mean(axis = 0))\n",
        "\n",
        "\n",
        "model_rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=10))\n",
        "model_rf.fit(X_train, y_train)\n",
        "y_predict_rf = model_rf.predict(X_test)\n",
        "\n",
        "abs_err_rf = abs(y_predict_rf - y_test)\n",
        "#all_err_rf_1.append(abs_err_rf.mean(axis = 0))\n",
        "\n",
        "\n",
        "#error_values_lr = np.asarray(all_err_lr_1)\n",
        "#error_values_lr = np.asarray(abs_err_lr.mean(axis=0))\n",
        "error_values_lr = np.asarray(abs_err_lr)\n",
        "mean_error_lr = error_values_lr.mean(axis = 0)\n",
        "#std_error_lr = 1/np.sqrt(31)*error_values_lr.std(axis = 0)\n",
        "std_error_lr = scipy.stats.sem(error_values_lr, axis=0, ddof=0, nan_policy='omit')\n",
        "\n",
        "print('-------------------------------------')\n",
        "print('Ridge Regression')\n",
        "print('MAE and STD error for Performance Labels')\n",
        "print(mean_error_lr)\n",
        "print(std_error_lr)\n",
        "print('-------------------------------------')\n",
        "\n",
        "#error_values_svr = np.asarray(all_err_svr_1)\n",
        "#error_values_svr = np.asarray(abs_err_lr.mean(axis=0))\n",
        "error_values_svr = np.asarray(abs_err_svr)\n",
        "mean_error_svr = error_values_svr.mean(axis = 0)\n",
        "#std_error_svr = 1/np.sqrt(31)*error_values_svr.std(axis = 0)\n",
        "std_error_svr = scipy.stats.sem(error_values_svr, axis=0, ddof=0, nan_policy='omit')\n",
        "\n",
        "print('-------------------------------------')\n",
        "print('Support Vector Regression')\n",
        "print('MAE and STD error for Performance Labels')\n",
        "print(mean_error_svr)\n",
        "print(std_error_svr)\n",
        "print('-------------------------------------')\n",
        "\n",
        "#error_values_gbr = np.asarray(all_err_gbr_1)\n",
        "#error_values_gbr = np.asarray(abs_err_gbr.mean(axis=0))\n",
        "error_values_gbr = np.asarray(abs_err_gbr)\n",
        "mean_error_gbr = error_values_gbr.mean(axis = 0)\n",
        "#std_error_gbr = 1/np.sqrt(31)*error_values_gbr.std(axis = 0)\n",
        "std_error_gbr = scipy.stats.sem(error_values_gbr, axis=0, ddof=0, nan_policy='omit')\n",
        "\n",
        "print('-------------------------------------')\n",
        "print('Gradient Boosting Regression')\n",
        "print('MAE and STD error for Performance Labels')\n",
        "print(mean_error_gbr)\n",
        "print(std_error_gbr)\n",
        "print('-------------------------------------')\n",
        "\n",
        "\n",
        "#error_values_rf = np.asarray(all_err_rf_1)\n",
        "#error_values_rf = np.asarray(abs_err_rf.mean(axis=0))\n",
        "error_values_rf = np.asarray(abs_err_rf)\n",
        "mean_error_rf = error_values_rf.mean(axis = 0)\n",
        "#std_error_rf = 1/np.sqrt(31)*error_values_rf.std(axis = 0)\n",
        "std_error_rf = scipy.stats.sem(error_values_rf, axis=0, ddof=0, nan_policy='omit')\n",
        "\n",
        "print('-------------------------------------')\n",
        "print('Random Forest Regression')\n",
        "print('MAE and STD error for Performance Labels')\n",
        "print(mean_error_rf)\n",
        "print(std_error_rf)\n",
        "print('-------------------------------------')\n",
        "\n",
        "perf = pd.DataFrame(np.stack((mean_error_lr, mean_error_svr, mean_error_gbr, mean_error_rf), axis = 0))\n",
        "perf_std_ = pd.DataFrame(np.stack((std_error_lr, std_error_svr, std_error_gbr, std_error_rf), axis = 0))\n",
        "\n",
        "x_lr = perf.iloc[0]\n",
        "x_svr = perf.iloc[1]\n",
        "x_gbr = perf.iloc[2]\n",
        "x_rf = perf.iloc[3]\n",
        "actual_x = ['t','t+Δt','t+2Δt']\n",
        "plt.title(\"Generalized performance model for 1 minute predictions\")\n",
        "plt.plot(actual_x, x_lr, label = \"lr\")\n",
        "plt.plot(actual_x, x_svr, label = \"svr\")\n",
        "plt.plot(actual_x, x_gbr, label = \"gbr\")\n",
        "plt.plot(actual_x, x_rf, label = \"rf\")\n",
        "\n",
        "plt.errorbar(actual_x, x_lr, yerr = perf_std_.iloc[0], fmt = 'o')\n",
        "plt.errorbar(actual_x, x_svr, yerr = perf_std_.iloc[1], fmt = 'o')\n",
        "plt.errorbar(actual_x, x_gbr, yerr = perf_std_.iloc[2], fmt = 'o')\n",
        "plt.errorbar(actual_x, x_rf, yerr = perf_std_.iloc[3], fmt = 'o')\n",
        "\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "VzgrSutVkfjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "#sampling at 5 minutes. Hence predicting 5, 10 and 15 minutes into future\n",
        "\n",
        "all_err_lr_2 = []\n",
        "all_err_svr_2 = []\n",
        "all_err_gbr_2 = []\n",
        "all_err_rf_2 = []\n",
        "\n",
        "parent_X = np.empty((1, n_timesteps_in,26))\n",
        "parent_y = np.empty((1, 3))\n",
        "\n",
        "for el in merged_files:\n",
        "  os.chdir(merged_data)\n",
        "  data = pd.read_csv(el)\n",
        "  data.drop(['Unnamed: 0','time_stamp','Fatigue Perception'], axis = 1, inplace = True)\n",
        "  data['Times'] =  pd.to_datetime(data['Times'])\n",
        "  data = data.set_index(['Times'])\n",
        "  data_1 = data.resample('5min').mean()\n",
        "  cols = list(data_1.columns)\n",
        "  cols = cols[1:]\n",
        "  #cols.append('response_correctness')\n",
        "  data_1 = data_1[cols]\n",
        "\n",
        "  n_timesteps_in = 3\n",
        "  n_timesteps_out = 3\n",
        "\n",
        "  # convert dataset into input/output\n",
        "  X, y = split_sequences(data_1.values, n_timesteps_in, n_timesteps_out)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle= True)\n",
        "\n",
        "  # convert 3D array into 2D\n",
        "  X_train = X_train.reshape((X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n",
        "  X_test = X_test.reshape((X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n",
        "\n",
        "  model_linreg = Ridge()\n",
        "  model_linreg.fit(X_train, y_train)\n",
        "  y_predict_lr_2 = model_linreg.predict(X_test)\n",
        "\n",
        "  abs_err_lr_2 = abs(y_predict_lr_2 - y_test)\n",
        "  #all_err_lr_2.append(abs_err_lr.mean(axis = 0))\n",
        "\n",
        "  model_svr = MultiOutputRegressor(SVR())\n",
        "  model_svr.fit(X_train, y_train)\n",
        "  y_predict_svr_2 = model_svr.predict(X_test)\n",
        "\n",
        "  abs_err_svr_2 = abs(y_predict_svr_2 - y_test)\n",
        "  #all_err_svr_2.append(abs_err_svr.mean(axis = 0))\n",
        "\n",
        "  model_gbr = MultiOutputRegressor(GradientBoostingRegressor())\n",
        "  model_gbr.fit(X_train, y_train)\n",
        "  y_predict_gbr_2 = model_gbr.predict(X_test)\n",
        "\n",
        "  abs_err_gbr_2 = abs(y_predict_gbr_2 - y_test)\n",
        "  #all_err_gbr_2.append(abs_err_gbr.mean(axis = 0))\n",
        "\n",
        "  model_rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=10))\n",
        "  model_rf.fit(X_train, y_train)\n",
        "  y_predict_rf_2 = model_rf.predict(X_test)\n",
        "\n",
        "  abs_err_rf_2 = abs(y_predict_rf_2 - y_test)\n",
        "  #all_err_rf_2.append(abs_err_rf.mean(axis = 0))\n",
        "\n",
        "\n",
        "error_values_lr_2 = np.asarray(abs_err_lr_2)\n",
        "mean_error_lr_2 = error_values_lr_2.mean(axis = 0)\n",
        "#std_error_lr_2 = 1/np.sqrt(31)*error_values_lr_2.std(axis = 0)\n",
        "std_error_lr_2 = scipy.stats.sem(error_values_lr_2 , axis=0, ddof=0, nan_policy='propagate')\n",
        "\n",
        "print('-------------------------------------')\n",
        "print('Ridge Regression')\n",
        "print('MAE and STD error for Performance Labels')\n",
        "print(mean_error_lr_2)\n",
        "print(std_error_lr_2)\n",
        "print('-------------------------------------')\n",
        "\n",
        "error_values_svr_2 = np.asarray(abs_err_svr_2)\n",
        "mean_error_svr_2 = error_values_svr_2.mean(axis = 0)\n",
        "#std_error_svr_2 = 1/np.sqrt(31)*error_values_svr_2.std(axis = 0)\n",
        "std_error_svr_2 = scipy.stats.sem(error_values_svr_2 , axis=0, ddof=0, nan_policy='propagate')\n",
        "\n",
        "print('-------------------------------------')\n",
        "print('Support Vector Regression')\n",
        "print('MAE and STD error for Performance Labels')\n",
        "print(mean_error_svr_2)\n",
        "print(std_error_svr_2)\n",
        "print('-------------------------------------')\n",
        "\n",
        "error_values_gbr_2 = np.asarray(abs_err_gbr_2)\n",
        "mean_error_gbr_2 = error_values_gbr_2.mean(axis = 0)\n",
        "#std_error_gbr_2 = 1/np.sqrt(31)*error_values_gbr_2.std(axis = 0)\n",
        "std_error_gbr_2 = scipy.stats.sem(error_values_gbr_2 , axis=0, ddof=0, nan_policy='propagate')\n",
        "\n",
        "print('-------------------------------------')\n",
        "print('Gradient Boosting Regression')\n",
        "print('MAE and STD error for Performance Labels')\n",
        "print(mean_error_gbr_2)\n",
        "print(std_error_gbr_2)\n",
        "print('-------------------------------------')\n",
        "\n",
        "\n",
        "error_values_rf_2 = np.asarray(abs_err_rf_2)\n",
        "mean_error_rf_2 = error_values_rf_2.mean(axis = 0)\n",
        "#std_error_rf_2 = 1/np.sqrt(31)*error_values_rf_2.std(axis = 0)\n",
        "std_error_rf_2 = scipy.stats.sem(error_values_rf_2 , axis=0, ddof=0, nan_policy='propagate')\n",
        "\n",
        "print('-------------------------------------')\n",
        "print('Random Forest Regression')\n",
        "print('MAE and STD error for Performance Labels')\n",
        "print(mean_error_rf_2)\n",
        "print(std_error_rf_2)\n",
        "print('-------------------------------------')\n",
        "\n",
        "perf_2 = pd.DataFrame(np.stack((mean_error_lr_2, mean_error_svr_2, mean_error_gbr_2, mean_error_rf_2), axis = 0))\n",
        "perf_std_2 = pd.DataFrame(np.stack((std_error_lr_2, std_error_svr_2, std_error_gbr_2, std_error_rf_2), axis = 0))\n",
        "\n",
        "\n",
        "x_lr_2 = perf_2.iloc[0]\n",
        "x_svr_2 = perf_2.iloc[1]\n",
        "x_gbr_2 = perf_2.iloc[2]\n",
        "x_rf_2 = perf_2.iloc[3]\n",
        "plt.title(\"Generalized performance model for 5 minute predictions\")\n",
        "actual_x = ['t','t+Δt','t+2Δt']\n",
        "plt.plot(actual_x, x_lr_2, label = \"lr\")\n",
        "plt.plot(actual_x, x_svr_2, label = \"svr\")\n",
        "plt.plot(actual_x, x_gbr_2, label = \"gbr\")\n",
        "plt.plot(actual_x, x_rf_2, label = \"rf\")\n",
        "\n",
        "plt.errorbar(actual_x, x_lr_2, yerr = perf_std_2.iloc[0], fmt = 'o')\n",
        "plt.errorbar(actual_x, x_svr_2, yerr = perf_std_2.iloc[1], fmt = 'o')\n",
        "plt.errorbar(actual_x, x_gbr_2, yerr = perf_std_2.iloc[2], fmt = 'o')\n",
        "plt.errorbar(actual_x, x_rf_2, yerr = perf_std_2.iloc[3], fmt = 'o')\n",
        "\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tjQrdAwMnRNu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S_H8nDpnd28_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sampling at 10 minutes. Hence predicting at time t, and 10 and 20 minutes minutes into future\n",
        "random.seed(10)\n",
        "all_err_lr_3 = []\n",
        "all_err_svr_3 = []\n",
        "all_err_gbr_3 = []\n",
        "all_err_rf_3 = []\n",
        "all_data = pd.DataFrame()\n",
        "n_timesteps_in = 3\n",
        "n_timesteps_out = 3\n",
        "\n",
        "parent_X = np.empty((1, n_timesteps_in,26))\n",
        "parent_y = np.empty((1, 3))\n",
        "\n",
        "for el in merged_files:\n",
        "  os.chdir(merged_data)\n",
        "  data = pd.read_csv(el, on_bad_lines='skip')\n",
        "  data.drop(['Unnamed: 0','time_stamp','Fatigue Perception'], axis = 1, inplace = True)\n",
        "  data['Times'] =  pd.to_datetime(data['Times'])\n",
        "  data = data.set_index(['Times'])\n",
        "  data_1 = data.resample('10min').mean()\n",
        "  cols = list(data_1.columns)\n",
        "  cols = cols[1:]\n",
        "  data_1 = data_1[cols]\n",
        "  all_data = all_data.append(data_1)\n",
        "\n",
        "# convert dataset into input/output\n",
        "X, y = split_sequences(all_data.values, n_timesteps_in, n_timesteps_out)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle= True)\n",
        "\n",
        "# convert 3D array into 2D\n",
        "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n",
        "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n",
        "\n",
        "model_linreg = Ridge()\n",
        "model_linreg.fit(X_train, y_train)\n",
        "y_predict_lr_3 = model_linreg.predict(X_test)\n",
        "\n",
        "abs_err_lr_3 = abs(y_predict_lr_3 - y_test)\n",
        "#all_err_lr_3.append(abs_err_lr.mean(axis = 0))\n",
        "\n",
        "model_svr = MultiOutputRegressor(SVR())\n",
        "model_svr.fit(X_train, y_train)\n",
        "y_predict_svr_3 = model_svr.predict(X_test)\n",
        "\n",
        "abs_err_svr_3 = abs(y_predict_svr_3 - y_test)\n",
        "#all_err_svr_3.append(abs_err_svr.mean(axis = 0))\n",
        "\n",
        "model_gbr = MultiOutputRegressor(GradientBoostingRegressor())\n",
        "model_gbr.fit(X_train, y_train)\n",
        "y_predict_gbr_3 = model_gbr.predict(X_test)\n",
        "\n",
        "abs_err_gbr_3 = abs(y_predict_gbr_3 - y_test)\n",
        "#all_err_gbr_3.append(abs_err_gbr.mean(axis = 0))\n",
        "\n",
        "model_rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=10))\n",
        "model_rf.fit(X_train, y_train)\n",
        "y_predict_rf_3 = model_rf.predict(X_test)\n",
        "\n",
        "abs_err_rf_3 = abs(y_predict_rf_3 - y_test)\n",
        "#all_err_rf_3.append(abs_err_rf.mean(axis = 0))\n",
        "\n",
        "\n",
        "error_values_lr_3 = np.asarray(abs_err_lr_3)\n",
        "mean_error_lr_3 = error_values_lr_3.mean(axis = 0)\n",
        "#std_error_lr_3 = 1/np.sqrt(31)*error_values_lr_3.std(axis = 0)\n",
        "std_error_lr_3 = scipy.stats.sem(error_values_lr_3 , axis=0, ddof=0, nan_policy='propagate')\n",
        "\n",
        "print('-------------------------------------')\n",
        "print('Ridge Regression')\n",
        "print('MAE and STD error for Performance Labels')\n",
        "print(mean_error_lr_3)\n",
        "print(std_error_lr_3)\n",
        "print('-------------------------------------')\n",
        "\n",
        "error_values_svr_3 = np.asarray(abs_err_svr_3)\n",
        "mean_error_svr_3 = error_values_svr_3.mean(axis = 0)\n",
        "#std_error_svr_3 = 1/np.sqrt(31)*error_values_svr_3.std(axis = 0)\n",
        "std_error_svr_3 = scipy.stats.sem(error_values_svr_3 , axis=0, ddof=0, nan_policy='propagate')\n",
        "\n",
        "print('-------------------------------------')\n",
        "print('Support Vector Regression')\n",
        "print('MAE and STD error for Performance Labels')\n",
        "print(mean_error_svr_3)\n",
        "print(std_error_svr_3)\n",
        "print('-------------------------------------')\n",
        "\n",
        "error_values_gbr_3 = np.asarray(abs_err_gbr_3)\n",
        "mean_error_gbr_3 = error_values_gbr_3.mean(axis = 0)\n",
        "#std_error_gbr_3 = 1/np.sqrt(31)*error_values_gbr_3.std(axis = 0)\n",
        "std_error_gbr_3 = scipy.stats.sem(error_values_gbr_3 , axis=0, ddof=0, nan_policy='propagate')\n",
        "\n",
        "print('-------------------------------------')\n",
        "print('Gradient Boosting Regression')\n",
        "print('MAE and STD error for Performance Labels')\n",
        "print(mean_error_gbr_3)\n",
        "print(std_error_gbr_3)\n",
        "print('-------------------------------------')\n",
        "\n",
        "\n",
        "error_values_rf_3 = np.asarray(abs_err_rf_3)\n",
        "mean_error_rf_3 = error_values_rf_3.mean(axis = 0)\n",
        "#std_error_rf_3 = 1/np.sqrt(31)*error_values_rf_3.std(axis = 0)\n",
        "std_error_rf_3 = scipy.stats.sem(error_values_rf_3 , axis=0, ddof=0, nan_policy='propagate')\n",
        "\n",
        "print('-------------------------------------')\n",
        "print('Random Forest Regression')\n",
        "print('MAE and STD error for Performance Labels')\n",
        "print(mean_error_rf_3)\n",
        "print(std_error_rf_3)\n",
        "print('-------------------------------------')\n",
        "\n",
        "perf_3 = pd.DataFrame(np.stack((mean_error_lr_3, mean_error_svr_3, mean_error_gbr_3, mean_error_rf_3), axis = 0))\n",
        "perf_std_3 = pd.DataFrame(np.stack((std_error_lr_3, std_error_svr_3, std_error_gbr_3, std_error_rf_3), axis = 0))\n",
        "\n",
        "\n",
        "x_lr_3 = perf_3.iloc[0]\n",
        "x_svr_3 = perf_3.iloc[1]\n",
        "x_gbr_3 = perf_3.iloc[2]\n",
        "x_rf_3 = perf_3.iloc[3]\n",
        "actual_x = ['t','t+Δt','t+2Δt']\n",
        "plt.title(\"Generalized performance model for 10 minute predictions\")\n",
        "plt.ylabel(\"Mean absolute error\")\n",
        "plt.plot(actual_x, x_lr_3, label = \"lr\", linestyle = 'solid')\n",
        "plt.plot(actual_x, x_svr_3, label = \"svr\", linestyle = 'dotted')\n",
        "plt.plot(actual_x, x_gbr_3, label = \"gbr\", linestyle = 'dashed')\n",
        "plt.plot(actual_x, x_rf_3, label = \"rf\", linestyle = 'dashdot')\n",
        "\n",
        "plt.errorbar(actual_x, x_lr_3, yerr = perf_std_3.iloc[0], fmt = 'o')\n",
        "plt.errorbar(actual_x, x_svr_3, yerr = perf_std_3.iloc[1], fmt = 'o')\n",
        "plt.errorbar(actual_x, x_gbr_3, yerr = perf_std_3.iloc[2], fmt = 'o')\n",
        "plt.errorbar(actual_x, x_rf_3, yerr = perf_std_3.iloc[3], fmt = 'o')\n",
        "\n",
        "#plt.legend(loc=\"bottom\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.xlabel(\"Forecast interval: Δt=10min\")\n",
        "plt.legend(bbox_to_anchor=(1.02, 1), loc='best', borderaxespad=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5XxZFH4Yo2l5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(10)\n",
        "X1 = all_data[['sdnn', 'sdsd', 'nni_50', 'pnni_50',\n",
        "       'nni_20', 'pnni_20', 'rmssd', 'median_nni', 'range_nni', 'cvsd',\n",
        "       'cvnni', 'mean_hr', 'max_hr', 'min_hr', 'std_hr', 'lf', 'hf',\n",
        "       'lf_hf_ratio', 'lfnu', 'hfnu', 'total_power', 'vlf', 'sd1', 'sd2',\n",
        "       'ratio_sd2_sd1', 'sampen']]\n",
        "\n",
        "#X values are missing mean_nni\n",
        "y1 = all_data['Performance']\n",
        "#all_data1 = all_data.dropna(inplace = True)\n",
        "#X1 = pd.DataFrame(all_data1.loc[:,0:25], columns = cols)\n",
        "#y1 = pd.DataFrame(all_data1.loc[:,-1:])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X1,y1 ,random_state=104, test_size=0.20, shuffle=False)\n",
        "regressor = RandomForestRegressor(n_estimators=10, random_state = 0)\n",
        "regressor.fit(X_train, y_train)\n",
        "y_pred = regressor.predict(X_test)\n",
        "#mae_ = sum(abs(y_pred-y_test))/len(y_test)\n",
        "mae_ = abs(y_pred-y_test)"
      ],
      "metadata": {
        "id": "jaRsEsqhcR4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_error_mae = np.array(mae_).mean(axis = 0)\n",
        "std_error_mae = scipy.stats.sem(np.array(mae_), axis = 0, ddof=0,nan_policy='propagate')\n",
        "print(\"MAE is \",mean_error_mae,\" and the standard error is +/- \",std_error_mae)"
      ],
      "metadata": {
        "id": "0IdngVOq9150"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor_gbr = GradientBoostingRegressor()\n",
        "regressor_gbr.fit(X_train, y_train)\n",
        "y_pred_gbr = regressor_gbr.predict(X_test)\n",
        "mae_gbr = abs(y_pred_gbr - y_test)\n",
        "\n",
        "mean_error_mae_gbr = np.array(mae_gbr).mean(axis = 0)\n",
        "std_error_mae_gbr = scipy.stats.sem(np.array(mae_gbr), axis = 0, ddof=0,nan_policy='propagate')\n",
        "print(\"MAE is \",mean_error_mae_gbr,\" and the standard error is +/- \",std_error_mae_gbr)"
      ],
      "metadata": {
        "id": "BOonwxjiMv_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor_gbr.feature_importances_\n",
        "sorted_idx = regressor_gbr.feature_importances_.argsort()\n",
        "sorted_idx = sorted_idx[16:26]\n",
        "c = 'grey'\n",
        "plt.barh(X1.columns[sorted_idx], regressor_gbr.feature_importances_[sorted_idx], color = c)\n",
        "plt.ylabel(\"Heart Rate Variability Features\")\n",
        "plt.xlabel(\"Feature importance [0,1]\")\n",
        "plt.title(\"Performance Labeled Model Feature Importance\")\n",
        "plt.savefig(\"performanceFeatureImportance.eps\", dpi=1200)\n",
        "#plt.bar(regressor_gbr.feature_importances_[sorted_idx], X1.columns[sorted_idx], color = c)\n",
        "plt.savefig('performancefeatureimportance.png', format = 'png', dpi=1200)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yuOsTKbiMwM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.feature_importances_\n",
        "sorted_idx = regressor.feature_importances_.argsort()\n",
        "c = 'grey'\n",
        "plt.barh(X1.columns[sorted_idx][16:26], regressor.feature_importances_[sorted_idx][16:26], color = c)\n",
        "plt.ylabel(\"Heart Rate Variability Features\")\n",
        "plt.xlabel(\"Feature importance\")\n",
        "plt.title(\"Feature Importance of HRV Features in Performance Scores Prediction\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QIK0vvmr948T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regr_Enet = ElasticNet()\n",
        "regr_multi_Enet= MultiOutputRegressor(regr_Enet)\n",
        "regr_multi_Enet.fit(X_train, y_train.values.reshape(-1,1))\n",
        "\n",
        "regr_multi_Enet.estimators_[0].coef_"
      ],
      "metadata": {
        "id": "ZBD4l-kh9wpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_idx_1 = regr_multi_Enet.estimators_[0].coef_.argsort()\n",
        "sorted_idx_1 = sorted_idx_1#[21:26]\n",
        "#plt.barh(X1.columns[sorted_idx], regressor.feature_importances_[sorted_idx])\n",
        "plt.barh(X_test.columns[sorted_idx_1], regr_multi_Enet.estimators_[0].coef_[sorted_idx_1])\n",
        "plt.title(\"RF generalized performance feature importance\")"
      ],
      "metadata": {
        "id": "eV5_EM7v98Az"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}