{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xvdNjll_atxy4qieD2_94nUOmP8ie8jJ","timestamp":1675837989073}],"authorship_tag":"ABX9TyMWc+N6FQW4MxMvBsjTUH5L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kf0YnqSNmgTD","executionInfo":{"status":"ok","timestamp":1767420468421,"user_tz":360,"elapsed":34474,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}},"outputId":"e00f2a04-367d-4f3e-ca77-1f9d3d665539"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"3xynYwHTkSWz","executionInfo":{"status":"ok","timestamp":1767420470720,"user_tz":360,"elapsed":2302,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}}},"outputs":[],"source":["# evaluate linear algorithms\n","from numpy import load\n","from numpy import loadtxt\n","from numpy import nan\n","from numpy import isnan\n","from numpy import count_nonzero\n","from numpy import unique\n","from numpy import array\n","from sklearn.base import clone\n","from scipy.stats import sem\n","import matplotlib.pyplot as plt\n","\n","from sklearn.linear_model import Ridge\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVR\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.linear_model import ElasticNet\n","\n","import os\n","import pandas as pd\n","import glob\n","import math\n","import datetime\n","import time\n","import numpy as np\n","import scipy\n","import random\n","\n","random.seed(10)\n","\n","# split a multivariate sequence into samples\n","def split_sequences(sequences, n_steps_in, n_steps_out):\n","\tX, y = list(), list()\n","\tfor i in range(len(sequences)):\n","\t\t# find the end of this pattern\n","\t\tend_ix = i + n_steps_in\n","\t\tout_end_ix = end_ix + n_steps_out-1\n","\t\t# check if we are beyond the dataset\n","\t\tif out_end_ix > len(sequences):\n","\t\t\tbreak\n","\t\t# gather input and output parts of the pattern\n","\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1:out_end_ix, -1]\n","\t\tX.append(seq_x)\n","\t\ty.append(seq_y)\n","\treturn np.array(X), np.array(y)"]},{"cell_type":"code","source":["def convert_to_preferred_format(sec):\n","    sec = sec % (24 * 3600)\n","    hour = sec // 3600\n","    sec %= 3600\n","    min = sec // 60\n","    sec %= 60\n","#  print(\"seconds value in hours:\",hour)\n","#  print(\"seconds value in minutes:\",min)\n","\n","#return \"%02d:%02d:%02d\" % (hour, min, sec)\n","    return \"%02d:%02d\" % (hour, min)"],"metadata":{"id":"07etnnwWlKIL","executionInfo":{"status":"ok","timestamp":1767420470741,"user_tz":360,"elapsed":19,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["merged_data = '/content/drive/MyDrive/NHANCE data analysis/NonNormalizedMergedData10min'\n","merged_files = os.listdir(merged_data)"],"metadata":{"id":"xHTt7oTpl6Zu","executionInfo":{"status":"ok","timestamp":1767420473128,"user_tz":360,"elapsed":2386,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["all_data = pd.DataFrame()"],"metadata":{"id":"PGTT7-lVupKj","executionInfo":{"status":"ok","timestamp":1767420473134,"user_tz":360,"elapsed":2,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#@title Default title text\n","n_timesteps_in = 3\n","n_timesteps_out = 3\n","\n","#parent_X = np.empty((1, n_timesteps_in, 26))\n","parent_X = np.empty((1, n_timesteps_in,26))\n","parent_y = np.empty((1, 3))\n","\n","for el in merged_files:\n","  os.chdir(merged_data)\n","  data = pd.read_csv(el)\n","  data.drop(['Unnamed: 0','time_stamp','Fatigue Perception'], axis = 1, inplace = True)\n","  data['Times'] =  pd.to_datetime(data['Times'])\n","  data = data.set_index(['Times'])\n","  data_1 = data.resample('1min').mean()\n","  cols = list(data_1.columns)\n","  cols = cols[1:]\n","  data_1 = data_1[cols]\n","  #all_data = all_data.append(data_1)\n","  X, y = split_sequences(data_1.values, n_timesteps_in, n_timesteps_out)\n","  parent_X = np.vstack((parent_X, X))\n","\n","  parent_y = np.vstack((parent_y, y))\n","\n","\n","#sampling at 1 minute. Hence predicting, 1, 2 and 3 minutes into future\n","all_err_lr_1 = []\n","all_err_svr_1 = []\n","all_err_gbr_1 = []\n","all_err_rf_1 = []\n","\n","\n","# convert dataset into input/output\n","#X, y = split_sequences(all_data.values, n_timesteps_in, n_timesteps_out)\n","X_train, X_test, y_train, y_test = train_test_split(parent_X, parent_y, test_size=0.2, shuffle= True)\n","\n","# convert 3D array into 2D\n","X_train = X_train.reshape((X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n","X_test = X_test.reshape((X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n","\n","model_linreg = Ridge()\n","model_linreg.fit(X_train, y_train)\n","y_predict_lr = model_linreg.predict(X_test)\n","\n","abs_err_lr = abs(y_predict_lr - y_test)\n","#all_err_lr_1.append(abs_err_lr.mean(axis = 0))\n","\n","model_svr = MultiOutputRegressor(SVR())\n","model_svr.fit(X_train, y_train)\n","y_predict_svr = model_svr.predict(X_test)\n","\n","abs_err_svr = abs(y_predict_svr - y_test)\n","#all_err_svr_1.append(abs_err_svr.mean(axis = 0))\n","\n","model_gbr = MultiOutputRegressor(GradientBoostingRegressor())\n","model_gbr.fit(X_train, y_train)\n","y_predict_gbr = model_gbr.predict(X_test)\n","\n","abs_err_gbr = abs(y_predict_gbr - y_test)\n","#all_err_gbr_1.append(abs_err_gbr.mean(axis = 0))\n","\n","\n","model_rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=10))\n","model_rf.fit(X_train, y_train)\n","y_predict_rf = model_rf.predict(X_test)\n","\n","abs_err_rf = abs(y_predict_rf - y_test)\n","#all_err_rf_1.append(abs_err_rf.mean(axis = 0))\n","\n","\n","#error_values_lr = np.asarray(all_err_lr_1)\n","#error_values_lr = np.asarray(abs_err_lr.mean(axis=0))\n","error_values_lr = np.asarray(abs_err_lr)\n","mean_error_lr = error_values_lr.mean(axis = 0)\n","#std_error_lr = 1/np.sqrt(31)*error_values_lr.std(axis = 0)\n","std_error_lr = scipy.stats.sem(error_values_lr, axis=0, ddof=0, nan_policy='omit')\n","\n","print('-------------------------------------')\n","print('Ridge Regression')\n","print('MAE and STD error for Performance Labels')\n","print(mean_error_lr)\n","print(std_error_lr)\n","print('-------------------------------------')\n","\n","#error_values_svr = np.asarray(all_err_svr_1)\n","#error_values_svr = np.asarray(abs_err_lr.mean(axis=0))\n","error_values_svr = np.asarray(abs_err_svr)\n","mean_error_svr = error_values_svr.mean(axis = 0)\n","#std_error_svr = 1/np.sqrt(31)*error_values_svr.std(axis = 0)\n","std_error_svr = scipy.stats.sem(error_values_svr, axis=0, ddof=0, nan_policy='omit')\n","\n","print('-------------------------------------')\n","print('Support Vector Regression')\n","print('MAE and STD error for Performance Labels')\n","print(mean_error_svr)\n","print(std_error_svr)\n","print('-------------------------------------')\n","\n","#error_values_gbr = np.asarray(all_err_gbr_1)\n","#error_values_gbr = np.asarray(abs_err_gbr.mean(axis=0))\n","error_values_gbr = np.asarray(abs_err_gbr)\n","mean_error_gbr = error_values_gbr.mean(axis = 0)\n","#std_error_gbr = 1/np.sqrt(31)*error_values_gbr.std(axis = 0)\n","std_error_gbr = scipy.stats.sem(error_values_gbr, axis=0, ddof=0, nan_policy='omit')\n","\n","print('-------------------------------------')\n","print('Gradient Boosting Regression')\n","print('MAE and STD error for Performance Labels')\n","print(mean_error_gbr)\n","print(std_error_gbr)\n","print('-------------------------------------')\n","\n","\n","#error_values_rf = np.asarray(all_err_rf_1)\n","#error_values_rf = np.asarray(abs_err_rf.mean(axis=0))\n","error_values_rf = np.asarray(abs_err_rf)\n","mean_error_rf = error_values_rf.mean(axis = 0)\n","#std_error_rf = 1/np.sqrt(31)*error_values_rf.std(axis = 0)\n","std_error_rf = scipy.stats.sem(error_values_rf, axis=0, ddof=0, nan_policy='omit')\n","\n","print('-------------------------------------')\n","print('Random Forest Regression')\n","print('MAE and STD error for Performance Labels')\n","print(mean_error_rf)\n","print(std_error_rf)\n","print('-------------------------------------')\n","\n","perf = pd.DataFrame(np.stack((mean_error_lr, mean_error_svr, mean_error_gbr, mean_error_rf), axis = 0))\n","perf_std_ = pd.DataFrame(np.stack((std_error_lr, std_error_svr, std_error_gbr, std_error_rf), axis = 0))\n","\n","x_lr = perf.iloc[0]\n","x_svr = perf.iloc[1]\n","x_gbr = perf.iloc[2]\n","x_rf = perf.iloc[3]\n","actual_x = ['t','t+Δt','t+2Δt']\n","plt.title(\"Generalized performance model for 1 minute predictions\")\n","plt.plot(actual_x, x_lr, label = \"lr\")\n","plt.plot(actual_x, x_svr, label = \"svr\")\n","plt.plot(actual_x, x_gbr, label = \"gbr\")\n","plt.plot(actual_x, x_rf, label = \"rf\")\n","\n","plt.errorbar(actual_x, x_lr, yerr = perf_std_.iloc[0], fmt = 'o')\n","plt.errorbar(actual_x, x_svr, yerr = perf_std_.iloc[1], fmt = 'o')\n","plt.errorbar(actual_x, x_gbr, yerr = perf_std_.iloc[2], fmt = 'o')\n","plt.errorbar(actual_x, x_rf, yerr = perf_std_.iloc[3], fmt = 'o')\n","\n","plt.legend(loc=\"upper right\")\n","plt.show()\n","\n"],"metadata":{"id":"VzgrSutVkfjT","colab":{"base_uri":"https://localhost:8080/","height":436},"executionInfo":{"status":"error","timestamp":1767420529295,"user_tz":360,"elapsed":975,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}},"outputId":"dc56b4cd-9c8e-4bbb-c0f3-3ca158f46845"},"execution_count":7,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Input X contains NaN.\nRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4053065350.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mmodel_linreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mmodel_linreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0my_predict_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_linreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0m_accept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_valid_accept_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         X, y = validate_data(\n\u001b[0m\u001b[1;32m   1240\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m   1108\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     _assert_all_finite_element_wise(\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             )\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRidge does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"]}]},{"cell_type":"code","source":["#@title Default title text\n","#sampling at 5 minutes. Hence predicting 5, 10 and 15 minutes into future\n","\n","all_err_lr_2 = []\n","all_err_svr_2 = []\n","all_err_gbr_2 = []\n","all_err_rf_2 = []\n","\n","parent_X = np.empty((1, n_timesteps_in,26))\n","parent_y = np.empty((1, 3))\n","\n","for el in merged_files:\n","  os.chdir(merged_data)\n","  data = pd.read_csv(el)\n","  data.drop(['Unnamed: 0','time_stamp','Fatigue Perception'], axis = 1, inplace = True)\n","  data['Times'] =  pd.to_datetime(data['Times'])\n","  data = data.set_index(['Times'])\n","  data_1 = data.resample('5min').mean()\n","  cols = list(data_1.columns)\n","  cols = cols[1:]\n","  #cols.append('response_correctness')\n","  data_1 = data_1[cols]\n","\n","  n_timesteps_in = 3\n","  n_timesteps_out = 3\n","\n","  # convert dataset into input/output\n","  X, y = split_sequences(data_1.values, n_timesteps_in, n_timesteps_out)\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle= True)\n","\n","  # convert 3D array into 2D\n","  X_train = X_train.reshape((X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n","  X_test = X_test.reshape((X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n","\n","  model_linreg = Ridge()\n","  model_linreg.fit(X_train, y_train)\n","  y_predict_lr_2 = model_linreg.predict(X_test)\n","\n","  abs_err_lr_2 = abs(y_predict_lr_2 - y_test)\n","  #all_err_lr_2.append(abs_err_lr.mean(axis = 0))\n","\n","  model_svr = MultiOutputRegressor(SVR())\n","  model_svr.fit(X_train, y_train)\n","  y_predict_svr_2 = model_svr.predict(X_test)\n","\n","  abs_err_svr_2 = abs(y_predict_svr_2 - y_test)\n","  #all_err_svr_2.append(abs_err_svr.mean(axis = 0))\n","\n","  model_gbr = MultiOutputRegressor(GradientBoostingRegressor())\n","  model_gbr.fit(X_train, y_train)\n","  y_predict_gbr_2 = model_gbr.predict(X_test)\n","\n","  abs_err_gbr_2 = abs(y_predict_gbr_2 - y_test)\n","  #all_err_gbr_2.append(abs_err_gbr.mean(axis = 0))\n","\n","  model_rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=10))\n","  model_rf.fit(X_train, y_train)\n","  y_predict_rf_2 = model_rf.predict(X_test)\n","\n","  abs_err_rf_2 = abs(y_predict_rf_2 - y_test)\n","  #all_err_rf_2.append(abs_err_rf.mean(axis = 0))\n","\n","\n","error_values_lr_2 = np.asarray(abs_err_lr_2)\n","mean_error_lr_2 = error_values_lr_2.mean(axis = 0)\n","#std_error_lr_2 = 1/np.sqrt(31)*error_values_lr_2.std(axis = 0)\n","std_error_lr_2 = scipy.stats.sem(error_values_lr_2 , axis=0, ddof=0, nan_policy='propagate')\n","\n","print('-------------------------------------')\n","print('Ridge Regression')\n","print('MAE and STD error for Performance Labels')\n","print(mean_error_lr_2)\n","print(std_error_lr_2)\n","print('-------------------------------------')\n","\n","error_values_svr_2 = np.asarray(abs_err_svr_2)\n","mean_error_svr_2 = error_values_svr_2.mean(axis = 0)\n","#std_error_svr_2 = 1/np.sqrt(31)*error_values_svr_2.std(axis = 0)\n","std_error_svr_2 = scipy.stats.sem(error_values_svr_2 , axis=0, ddof=0, nan_policy='propagate')\n","\n","print('-------------------------------------')\n","print('Support Vector Regression')\n","print('MAE and STD error for Performance Labels')\n","print(mean_error_svr_2)\n","print(std_error_svr_2)\n","print('-------------------------------------')\n","\n","error_values_gbr_2 = np.asarray(abs_err_gbr_2)\n","mean_error_gbr_2 = error_values_gbr_2.mean(axis = 0)\n","#std_error_gbr_2 = 1/np.sqrt(31)*error_values_gbr_2.std(axis = 0)\n","std_error_gbr_2 = scipy.stats.sem(error_values_gbr_2 , axis=0, ddof=0, nan_policy='propagate')\n","\n","print('-------------------------------------')\n","print('Gradient Boosting Regression')\n","print('MAE and STD error for Performance Labels')\n","print(mean_error_gbr_2)\n","print(std_error_gbr_2)\n","print('-------------------------------------')\n","\n","\n","error_values_rf_2 = np.asarray(abs_err_rf_2)\n","mean_error_rf_2 = error_values_rf_2.mean(axis = 0)\n","#std_error_rf_2 = 1/np.sqrt(31)*error_values_rf_2.std(axis = 0)\n","std_error_rf_2 = scipy.stats.sem(error_values_rf_2 , axis=0, ddof=0, nan_policy='propagate')\n","\n","print('-------------------------------------')\n","print('Random Forest Regression')\n","print('MAE and STD error for Performance Labels')\n","print(mean_error_rf_2)\n","print(std_error_rf_2)\n","print('-------------------------------------')\n","\n","perf_2 = pd.DataFrame(np.stack((mean_error_lr_2, mean_error_svr_2, mean_error_gbr_2, mean_error_rf_2), axis = 0))\n","perf_std_2 = pd.DataFrame(np.stack((std_error_lr_2, std_error_svr_2, std_error_gbr_2, std_error_rf_2), axis = 0))\n","\n","\n","x_lr_2 = perf_2.iloc[0]\n","x_svr_2 = perf_2.iloc[1]\n","x_gbr_2 = perf_2.iloc[2]\n","x_rf_2 = perf_2.iloc[3]\n","plt.title(\"Generalized performance model for 5 minute predictions\")\n","actual_x = ['t','t+Δt','t+2Δt']\n","plt.plot(actual_x, x_lr_2, label = \"lr\")\n","plt.plot(actual_x, x_svr_2, label = \"svr\")\n","plt.plot(actual_x, x_gbr_2, label = \"gbr\")\n","plt.plot(actual_x, x_rf_2, label = \"rf\")\n","\n","plt.errorbar(actual_x, x_lr_2, yerr = perf_std_2.iloc[0], fmt = 'o')\n","plt.errorbar(actual_x, x_svr_2, yerr = perf_std_2.iloc[1], fmt = 'o')\n","plt.errorbar(actual_x, x_gbr_2, yerr = perf_std_2.iloc[2], fmt = 'o')\n","plt.errorbar(actual_x, x_rf_2, yerr = perf_std_2.iloc[3], fmt = 'o')\n","\n","plt.legend(loc=\"upper right\")\n","plt.show()\n"],"metadata":{"id":"tjQrdAwMnRNu","cellView":"form","executionInfo":{"status":"aborted","timestamp":1767420486726,"user_tz":360,"elapsed":5,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"S_H8nDpnd28_","executionInfo":{"status":"aborted","timestamp":1767420486727,"user_tz":360,"elapsed":52985,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#sampling at 10 minutes. Hence predicting at time t, and 10 and 20 minutes minutes into future\n","random.seed(10)\n","all_err_lr_3 = []\n","all_err_svr_3 = []\n","all_err_gbr_3 = []\n","all_err_rf_3 = []\n","all_data = pd.DataFrame()\n","n_timesteps_in = 3\n","n_timesteps_out = 3\n","\n","parent_X = np.empty((1, n_timesteps_in,26))\n","parent_y = np.empty((1, 3))\n","\n","for el in merged_files:\n","  os.chdir(merged_data)\n","  data = pd.read_csv(el, on_bad_lines='skip')\n","  data.drop(['Unnamed: 0','time_stamp','Fatigue Perception'], axis = 1, inplace = True)\n","  data['Times'] =  pd.to_datetime(data['Times'])\n","  data = data.set_index(['Times'])\n","  data_1 = data.resample('10min').mean()\n","  cols = list(data_1.columns)\n","  cols = cols[1:]\n","  data_1 = data_1[cols]\n","  all_data = all_data.append(data_1)\n","\n","# convert dataset into input/output\n","X, y = split_sequences(all_data.values, n_timesteps_in, n_timesteps_out)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle= True)\n","\n","# convert 3D array into 2D\n","X_train = X_train.reshape((X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n","X_test = X_test.reshape((X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n","\n","model_linreg = Ridge()\n","model_linreg.fit(X_train, y_train)\n","y_predict_lr_3 = model_linreg.predict(X_test)\n","\n","abs_err_lr_3 = abs(y_predict_lr_3 - y_test)\n","#all_err_lr_3.append(abs_err_lr.mean(axis = 0))\n","\n","model_svr = MultiOutputRegressor(SVR())\n","model_svr.fit(X_train, y_train)\n","y_predict_svr_3 = model_svr.predict(X_test)\n","\n","abs_err_svr_3 = abs(y_predict_svr_3 - y_test)\n","#all_err_svr_3.append(abs_err_svr.mean(axis = 0))\n","\n","model_gbr = MultiOutputRegressor(GradientBoostingRegressor())\n","model_gbr.fit(X_train, y_train)\n","y_predict_gbr_3 = model_gbr.predict(X_test)\n","\n","abs_err_gbr_3 = abs(y_predict_gbr_3 - y_test)\n","#all_err_gbr_3.append(abs_err_gbr.mean(axis = 0))\n","\n","model_rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=10))\n","model_rf.fit(X_train, y_train)\n","y_predict_rf_3 = model_rf.predict(X_test)\n","\n","abs_err_rf_3 = abs(y_predict_rf_3 - y_test)\n","#all_err_rf_3.append(abs_err_rf.mean(axis = 0))\n","\n","\n","error_values_lr_3 = np.asarray(abs_err_lr_3)\n","mean_error_lr_3 = error_values_lr_3.mean(axis = 0)\n","#std_error_lr_3 = 1/np.sqrt(31)*error_values_lr_3.std(axis = 0)\n","std_error_lr_3 = scipy.stats.sem(error_values_lr_3 , axis=0, ddof=0, nan_policy='propagate')\n","\n","print('-------------------------------------')\n","print('Ridge Regression')\n","print('MAE and STD error for Performance Labels')\n","print(mean_error_lr_3)\n","print(std_error_lr_3)\n","print('-------------------------------------')\n","\n","error_values_svr_3 = np.asarray(abs_err_svr_3)\n","mean_error_svr_3 = error_values_svr_3.mean(axis = 0)\n","#std_error_svr_3 = 1/np.sqrt(31)*error_values_svr_3.std(axis = 0)\n","std_error_svr_3 = scipy.stats.sem(error_values_svr_3 , axis=0, ddof=0, nan_policy='propagate')\n","\n","print('-------------------------------------')\n","print('Support Vector Regression')\n","print('MAE and STD error for Performance Labels')\n","print(mean_error_svr_3)\n","print(std_error_svr_3)\n","print('-------------------------------------')\n","\n","error_values_gbr_3 = np.asarray(abs_err_gbr_3)\n","mean_error_gbr_3 = error_values_gbr_3.mean(axis = 0)\n","#std_error_gbr_3 = 1/np.sqrt(31)*error_values_gbr_3.std(axis = 0)\n","std_error_gbr_3 = scipy.stats.sem(error_values_gbr_3 , axis=0, ddof=0, nan_policy='propagate')\n","\n","print('-------------------------------------')\n","print('Gradient Boosting Regression')\n","print('MAE and STD error for Performance Labels')\n","print(mean_error_gbr_3)\n","print(std_error_gbr_3)\n","print('-------------------------------------')\n","\n","\n","error_values_rf_3 = np.asarray(abs_err_rf_3)\n","mean_error_rf_3 = error_values_rf_3.mean(axis = 0)\n","#std_error_rf_3 = 1/np.sqrt(31)*error_values_rf_3.std(axis = 0)\n","std_error_rf_3 = scipy.stats.sem(error_values_rf_3 , axis=0, ddof=0, nan_policy='propagate')\n","\n","print('-------------------------------------')\n","print('Random Forest Regression')\n","print('MAE and STD error for Performance Labels')\n","print(mean_error_rf_3)\n","print(std_error_rf_3)\n","print('-------------------------------------')\n","\n","perf_3 = pd.DataFrame(np.stack((mean_error_lr_3, mean_error_svr_3, mean_error_gbr_3, mean_error_rf_3), axis = 0))\n","perf_std_3 = pd.DataFrame(np.stack((std_error_lr_3, std_error_svr_3, std_error_gbr_3, std_error_rf_3), axis = 0))\n","\n","\n","x_lr_3 = perf_3.iloc[0]\n","x_svr_3 = perf_3.iloc[1]\n","x_gbr_3 = perf_3.iloc[2]\n","x_rf_3 = perf_3.iloc[3]\n","actual_x = ['t','t+Δt','t+2Δt']\n","plt.title(\"Generalized performance model for 10 minute predictions\")\n","plt.ylabel(\"Mean absolute error\")\n","plt.plot(actual_x, x_lr_3, label = \"lr\", linestyle = 'solid')\n","plt.plot(actual_x, x_svr_3, label = \"svr\", linestyle = 'dotted')\n","plt.plot(actual_x, x_gbr_3, label = \"gbr\", linestyle = 'dashed')\n","plt.plot(actual_x, x_rf_3, label = \"rf\", linestyle = 'dashdot')\n","\n","plt.errorbar(actual_x, x_lr_3, yerr = perf_std_3.iloc[0], fmt = 'o')\n","plt.errorbar(actual_x, x_svr_3, yerr = perf_std_3.iloc[1], fmt = 'o')\n","plt.errorbar(actual_x, x_gbr_3, yerr = perf_std_3.iloc[2], fmt = 'o')\n","plt.errorbar(actual_x, x_rf_3, yerr = perf_std_3.iloc[3], fmt = 'o')\n","\n","#plt.legend(loc=\"bottom\")\n","plt.ylabel(\"MAE\")\n","plt.xlabel(\"Forecast interval: Δt=10min\")\n","plt.legend(bbox_to_anchor=(1.02, 1), loc='best', borderaxespad=0)\n","plt.show()"],"metadata":{"id":"5XxZFH4Yo2l5","executionInfo":{"status":"aborted","timestamp":1767420486728,"user_tz":360,"elapsed":52985,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["random.seed(10)\n","X1 = all_data[['sdnn', 'sdsd', 'nni_50', 'pnni_50',\n","       'nni_20', 'pnni_20', 'rmssd', 'median_nni', 'range_nni', 'cvsd',\n","       'cvnni', 'mean_hr', 'max_hr', 'min_hr', 'std_hr', 'lf', 'hf',\n","       'lf_hf_ratio', 'lfnu', 'hfnu', 'total_power', 'vlf', 'sd1', 'sd2',\n","       'ratio_sd2_sd1', 'sampen']]\n","\n","#X values are missing mean_nni\n","y1 = all_data['Performance']\n","#all_data1 = all_data.dropna(inplace = True)\n","#X1 = pd.DataFrame(all_data1.loc[:,0:25], columns = cols)\n","#y1 = pd.DataFrame(all_data1.loc[:,-1:])\n","\n","X_train, X_test, y_train, y_test = train_test_split(X1,y1 ,random_state=104, test_size=0.20, shuffle=False)\n","regressor = RandomForestRegressor(n_estimators=10, random_state = 0)\n","regressor.fit(X_train, y_train)\n","y_pred = regressor.predict(X_test)\n","#mae_ = sum(abs(y_pred-y_test))/len(y_test)\n","mae_ = abs(y_pred-y_test)"],"metadata":{"id":"jaRsEsqhcR4S","executionInfo":{"status":"aborted","timestamp":1767420486736,"user_tz":360,"elapsed":52993,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_error_mae = np.array(mae_).mean(axis = 0)\n","std_error_mae = scipy.stats.sem(np.array(mae_), axis = 0, ddof=0,nan_policy='propagate')\n","print(\"MAE is \",mean_error_mae,\" and the standard error is +/- \",std_error_mae)"],"metadata":{"id":"0IdngVOq9150","executionInfo":{"status":"aborted","timestamp":1767420486737,"user_tz":360,"elapsed":52992,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["regressor_gbr = GradientBoostingRegressor()\n","regressor_gbr.fit(X_train, y_train)\n","y_pred_gbr = regressor_gbr.predict(X_test)\n","mae_gbr = abs(y_pred_gbr - y_test)\n","\n","mean_error_mae_gbr = np.array(mae_gbr).mean(axis = 0)\n","std_error_mae_gbr = scipy.stats.sem(np.array(mae_gbr), axis = 0, ddof=0,nan_policy='propagate')\n","print(\"MAE is \",mean_error_mae_gbr,\" and the standard error is +/- \",std_error_mae_gbr)"],"metadata":{"id":"BOonwxjiMv_1","executionInfo":{"status":"aborted","timestamp":1767420486738,"user_tz":360,"elapsed":52993,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["regressor_gbr.feature_importances_\n","sorted_idx = regressor_gbr.feature_importances_.argsort()\n","sorted_idx = sorted_idx[16:26]\n","c = 'grey'\n","plt.barh(X1.columns[sorted_idx], regressor_gbr.feature_importances_[sorted_idx], color = c)\n","plt.ylabel(\"Heart Rate Variability Features\")\n","plt.xlabel(\"Feature importance [0,1]\")\n","plt.title(\"Performance Labeled Model Feature Importance\")\n","plt.savefig(\"performanceFeatureImportance.eps\", dpi=1200)\n","#plt.bar(regressor_gbr.feature_importances_[sorted_idx], X1.columns[sorted_idx], color = c)\n","plt.savefig('performancefeatureimportance.png', format = 'png', dpi=1200)\n","plt.show()"],"metadata":{"id":"yuOsTKbiMwM9","executionInfo":{"status":"aborted","timestamp":1767420486738,"user_tz":360,"elapsed":52992,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["regressor.feature_importances_\n","sorted_idx = regressor.feature_importances_.argsort()\n","c = 'grey'\n","plt.barh(X1.columns[sorted_idx][16:26], regressor.feature_importances_[sorted_idx][16:26], color = c)\n","plt.ylabel(\"Heart Rate Variability Features\")\n","plt.xlabel(\"Feature importance\")\n","plt.title(\"Feature Importance of HRV Features in Performance Scores Prediction\")\n","plt.show()"],"metadata":{"id":"QIK0vvmr948T","executionInfo":{"status":"aborted","timestamp":1767420486738,"user_tz":360,"elapsed":52991,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["regr_Enet = ElasticNet()\n","regr_multi_Enet= MultiOutputRegressor(regr_Enet)\n","regr_multi_Enet.fit(X_train, y_train.values.reshape(-1,1))\n","\n","regr_multi_Enet.estimators_[0].coef_"],"metadata":{"id":"ZBD4l-kh9wpW","executionInfo":{"status":"aborted","timestamp":1767420486739,"user_tz":360,"elapsed":52991,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sorted_idx_1 = regr_multi_Enet.estimators_[0].coef_.argsort()\n","sorted_idx_1 = sorted_idx_1#[21:26]\n","#plt.barh(X1.columns[sorted_idx], regressor.feature_importances_[sorted_idx])\n","plt.barh(X_test.columns[sorted_idx_1], regr_multi_Enet.estimators_[0].coef_[sorted_idx_1])\n","plt.title(\"RF generalized performance feature importance\")"],"metadata":{"id":"eV5_EM7v98Az","executionInfo":{"status":"aborted","timestamp":1767420486743,"user_tz":360,"elapsed":52995,"user":{"displayName":"David Nartey","userId":"02916534152141707182"}}},"execution_count":null,"outputs":[]}]}